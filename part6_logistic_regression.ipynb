{"cells":[{"cell_type":"markdown","source":[" # part 6: logistic regression - with coefficients and CIs"],"metadata":{}},{"cell_type":"markdown","source":[" Reviewers were generally interested in they way models our models work and the reasons for why they generated their predictions. They asked us to comment more on model machinery, and to report the contributions of input variables to model outcomes in more detail.\n","\n"," In this notebook, we provide code to generate coefficients and confidence intervals for logistic regression models. We do this in a separate notebook for convenience and transparency, and and to prevent small changes in prior model results that we initially reported.\n","\n"," we use the python statsmodels library."],"metadata":{}},{"source":["import pandas as pd\n","import numpy as np\n","import python_modules.constants as constants\n","import statsmodels.api as sm\n","from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, accuracy_score, auc\n","from sklearn.linear_model import LogisticRegression\n","import matplotlib.pyplot as plt\n","\n","debug = False\n","set_intercept  = False\n","cat_vars = constants.CATEGORICAL_PRE\n","cat_ord  = constants.CATEGORICAL_ORDER\n","con_vars = constants.CONTINUOUS_PRE\n","ref_cats_dict = constants.REF_CATS\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["ref_cats_list = []\n","for keyname, valname in zip(ref_cats_dict.keys(), ref_cats_dict.values()):\n","    if valname.endswith('.'):\n","        ref_cats_list += [keyname]\n","ref_cats_list = ref_cats_list\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["ref_cats_list\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ## utils\n","\n"," one hot encode features"],"metadata":{}},{"source":["def one_hot_encode(df):\n","    df_oh = df.copy()\n","    vs = []\n","    for v in cat_vars:\n","        df_oh[v] = df_oh[v].astype('str')\n","        vs += [v]\n","    # the easiest way to do this would be to set drop_first=True in the next line\n","    # however, we want to specify our own reference levels for categorical vars\n","    # therefore we have to specify which cols to drop\n","    df_oh = pd.get_dummies(df_oh, columns = vs, drop_first=False)\n","\n","    df_oh.drop(columns=ref_cats_list, inplace=True)\n","\n","    return df_oh\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" score preds on auc"],"metadata":{}},{"source":["def generate_results_roc(y_test, y_score, plotting=False):\n","    fpr, tpr, _ = roc_curve(y_test, y_score)\n","    roc_auc = auc(fpr, tpr)\n","    if plotting == True:\n","        plt.figure()\n","        plt.plot(fpr, tpr, label='ROC curve (area = %0.2f' + str(roc_auc))\n","        plt.plot([0, 1], [0, 1], 'k--')\n","        plt.xlim([0.0, .2])\n","        plt.ylim([0.0, .6])\n","        plt.xlabel('False Positive Rate')\n","        plt.ylabel('True Positive Rate')\n","        plt.title('Receiver operating characteristic curve')\n","        plt.show()\n","    print('AUC: ' , roc_auc)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ## leak"],"metadata":{}},{"cell_type":"markdown","source":[" load data"],"metadata":{}},{"source":["leak_train = pd.read_csv('study_data/LEAK_training.csv')\n","leak_train_original = pd.read_csv('study_data/LEAK_training_original.csv')\n","leak_val = pd.read_csv('study_data/LEAK_validation.csv')\n","leak_test = pd.read_csv('study_data/LEAK_testing.csv')\n","\n","# drop unused col:\n","leak_train.drop(['Unnamed: 0'], axis=1, inplace=True)\n","leak_train_original.drop(['Unnamed: 0'], axis=1, inplace=True)\n","leak_val.drop(['Unnamed: 0'], axis=1, inplace=True)\n","leak_test.drop(['Unnamed: 0'], axis=1, inplace=True)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["print(leak_train_original['RENAL_INSUFFICIENCY'].value_counts())\n","print(leak_val['RENAL_INSUFFICIENCY'].value_counts())\n","print(leak_test['RENAL_INSUFFICIENCY'].value_counts())\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" we can explicitly confirm that we rebalanced data as intended in the previous notebook:"],"metadata":{}},{"source":["if debug == True:\n","    print(leak_train['LEAK'].value_counts())\n","    print(leak_train_original['LEAK'].value_counts())\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" split data out into features and labels for each of training, testing, and validation sets"],"metadata":{}},{"source":["leak_train_labels = leak_train['LEAK']\n","leak_train_features = leak_train.drop('LEAK', axis=1)\n","leak_valid_labels = leak_val['LEAK']\n","leak_valid_features = leak_val.drop('LEAK', axis=1)\n","leak_testing_labels = leak_test['LEAK']\n","leak_testing_features = leak_test.drop('LEAK', axis=1)\n","leak_training_original_labels = leak_train_original['LEAK']\n","leak_training_original_features = leak_train_original.drop('LEAK', axis=1)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" one-hot encode categorical vars"],"metadata":{}},{"source":["leak_train_features_oh = one_hot_encode(leak_train_features)\n","leak_train_features_original_oh = one_hot_encode(leak_training_original_features)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["leak_valid_features_oh = one_hot_encode(leak_valid_features)\n","leak_test_features_oh = one_hot_encode(leak_testing_features)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["leak_train_features_original_oh.columns\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### a note on intercepts\n","\n"," if we want to set an intercept for models, can set an intercept col as follows. this results in worse AUCs by a little bit, and since we are after prediction more than interpretability,  don't do it."],"metadata":{}},{"source":["if set_intercept == True:\n","    leak_train_features_oh['intercept'] = 1\n","    leak_valid_features_oh['intercept'] = 1\n","    leak_test_features_oh['intercept'] = 1\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### back to modelling leak risk"],"metadata":{}},{"cell_type":"markdown","source":[" train models. use two different solvers and make sure results agree. of note, all signif coefficients match up between these solvers (not shown) and also matched up on a test of this package against SAS (also not shown)."],"metadata":{}},{"source":["logit_mod_bfgs = sm.Logit(leak_train_labels, leak_train_features_oh)\n","logit_res_bfgs = logit_mod_bfgs.fit(maxiter=500, method='bfgs')\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["logit_mod_ncg = sm.Logit(leak_train_labels, leak_train_features_oh)\n","logit_res_ncg = logit_mod_ncg.fit(maxiter=500, method='ncg')\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["preds_bfgs = logit_res_bfgs.predict(exog=leak_test_features_oh)\n","preds_ncg = logit_res_ncg.predict(exog=leak_test_features_oh)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["generate_results_roc(leak_testing_labels, preds_bfgs)\n","generate_results_roc(leak_testing_labels, preds_ncg)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" we will report results using the ncg solver since it's done in the fewest steps and the results are essentially the same."],"metadata":{}},{"cell_type":"markdown","source":[" show that models agree on which values are insignificant"],"metadata":{}},{"source":["print(list(logit_res_ncg.pvalues[logit_res_ncg.pvalues > 0.01].index))\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["print(list(logit_res_bfgs.pvalues[logit_res_bfgs.pvalues > 0.01].index))\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" re-run models without insignificant columns to prove they aren't throwing the model off."],"metadata":{}},{"source":["insig_cols_leak = list(logit_res_bfgs.pvalues[logit_res_bfgs.pvalues > 0.01].index)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["leak_train_features_oh_sig = leak_train_features_oh.drop(columns=insig_cols_leak).copy()\n","leak_valid_features_oh_sig = leak_valid_features_oh.drop(columns=insig_cols_leak).copy()\n","leak_test_features_oh_sig  = leak_test_features_oh.drop(columns=insig_cols_leak).copy()\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["logit_mod_ncg_sig = sm.Logit(leak_train_labels, leak_train_features_oh_sig)\n","logit_res_ncg_sig = logit_mod_ncg_sig.fit(maxiter=500, method='ncg')\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["preds_ncg_sig = logit_res_ncg_sig.predict(exog=leak_test_features_oh_sig)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" the results are the same. we default to reporting the full model in order to maintain consistency with the machine learning model inputs."],"metadata":{}},{"source":["generate_results_roc(leak_testing_labels, preds_ncg_sig)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" the coefficient for unknown IVC filter status is enormous. drop it to prove that it is not throwing the model off"],"metadata":{}},{"source":["leak_train_features_oh_sig_no_ivc0 = leak_train_features_oh_sig.drop(columns=['IVCF_0']).copy()\n","leak_valid_features_oh_sig_no_ivc0 = leak_valid_features_oh_sig.drop(columns=['IVCF_0']).copy()\n","leak_test_features_oh_sig_no_ivc0  = leak_test_features_oh_sig.drop(columns=['IVCF_0']).copy()\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["logit_mod_ncg_sig_no_ivc0 = sm.Logit(leak_train_labels, leak_train_features_oh_sig_no_ivc0)\n","logit_res_ncg_sig_no_ivc0 = logit_mod_ncg_sig_no_ivc0.fit(maxiter=500, method='ncg')\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["preds_ncg_sigsig_no_ivc0 = logit_res_ncg_sig_no_ivc0.predict(exog=leak_test_features_oh_sig_no_ivc0)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["generate_results_roc(leak_testing_labels, preds_ncg_sigsig_no_ivc0)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" we can also show that grouping asa 5 with asa 4 does not improve model performance."],"metadata":{}},{"source":["leak_train_features_oh_no_asa_5 = leak_train_features_oh.copy()\n","leak_valid_features_oh_no_asa_5 = leak_valid_features_oh.copy()\n","leak_test_features_oh_no_asa_5 = leak_test_features_oh.copy()\n","\n","leak_train_features_oh_no_asa_5['ASACLASS_4'] = np.where(leak_train_features_oh_no_asa_5['ASACLASS_5']==1, 1, leak_train_features_oh_no_asa_5['ASACLASS_4'])\n","leak_valid_features_oh_no_asa_5['ASACLASS_4'] = np.where(leak_valid_features_oh_no_asa_5['ASACLASS_5']==1, 1, leak_valid_features_oh_no_asa_5['ASACLASS_4'])\n","leak_test_features_oh_no_asa_5['ASACLASS_4'] = np.where(leak_test_features_oh_no_asa_5['ASACLASS_5']==1, 1, leak_test_features_oh_no_asa_5['ASACLASS_4'])\n","\n","leak_train_features_oh_no_asa_5.drop(columns='ASACLASS_5', inplace=True)\n","leak_valid_features_oh_no_asa_5.drop(columns='ASACLASS_5', inplace=True)\n","leak_test_features_oh_no_asa_5.drop(columns='ASACLASS_5', inplace=True)\n","\n","logit_mod_ncg_asa45 = sm.Logit(leak_train_labels, leak_train_features_oh_no_asa_5)\n","logit_res_ncg_asa45 = logit_mod_ncg_asa45.fit(maxiter=500, method='ncg')\n","\n","preds_ncg_sig_asa45 = logit_res_ncg_asa45.predict(exog=leak_test_features_oh_no_asa_5)\n","\n","generate_results_roc(leak_testing_labels, preds_ncg_sig_asa45)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" and can show that the result holds if we drop insig cols again"],"metadata":{}},{"source":["print(list(logit_res_ncg_asa45.pvalues[logit_res_ncg.pvalues > 0.01].index))\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["insig_cols_leak_asa45 = list(logit_res_ncg_asa45.pvalues[logit_res_ncg_asa45.pvalues > 0.01].index)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["leak_train_features_oh_no_asa_5_sig = leak_train_features_oh_no_asa_5.drop(columns=insig_cols_leak_asa45).copy()\n","leak_test_features_oh_no_asa5_sig  = leak_test_features_oh_no_asa_5.drop(columns=insig_cols_leak_asa45).copy()\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["logit_mod_ncg_sig_no_asa_5 = sm.Logit(leak_train_labels, leak_train_features_oh_no_asa_5_sig)\n","logit_res_ncg_sig_no_asa_5 = logit_mod_ncg_sig.fit(maxiter=500, method='ncg')\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["preds_ncg_sig_no_asa_5 = logit_res_ncg_sig_no_asa_5.predict(exog=leak_test_features_oh_no_asa5_sig)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["generate_results_roc(leak_testing_labels, preds_ncg_sig_no_asa_5)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### in keeping with reporting guidelines, measure model performance on testing and validation data as well."],"metadata":{}},{"cell_type":"markdown","source":[" training - with oversampling"],"metadata":{}},{"source":["preds_ncg_train = logit_res_ncg.predict(exog=leak_train_features_oh)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["generate_results_roc(leak_train_labels, preds_ncg_train)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" training - without oversampling (this is what we report)"],"metadata":{}},{"source":["preds_ncg_train_original = logit_res_ncg.predict(exog=leak_train_features_original_oh)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["generate_results_roc(leak_training_original_labels, preds_ncg_train_original)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" validation"],"metadata":{}},{"source":["preds_ncg_valid = logit_res_ncg.predict(exog=leak_valid_features_oh)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["generate_results_roc(leak_valid_labels, preds_ncg_valid)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ## clot"],"metadata":{}},{"cell_type":"markdown","source":[" I will not go through all the scenarios that i did above. the code can be easily adapted to do so. the same results hold in this context. here we just show results on testing as well as training and validation sets."],"metadata":{}},{"source":["clot_train = pd.read_csv('study_data/CLOT_training.csv')\n","clot_train_original = pd.read_csv('study_data/CLOT_training_original.csv')\n","clot_val = pd.read_csv('study_data/CLOT_validation.csv')\n","clot_test = pd.read_csv('study_data/CLOT_testing.csv')\n","\n","# drop unused col:\n","clot_train.drop(['Unnamed: 0'], axis=1, inplace=True)\n","clot_train_original.drop(['Unnamed: 0'], axis=1, inplace=True)\n","clot_val.drop(['Unnamed: 0'], axis=1, inplace=True)\n","clot_test.drop(['Unnamed: 0'], axis=1, inplace=True)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" split data out into features and labels for each of training, testing, and validation sets"],"metadata":{}},{"source":["clot_train_labels = clot_train['CLOT']\n","clot_train_features = clot_train.drop('CLOT', axis=1)\n","clot_valid_labels = clot_val['CLOT']\n","clot_valid_features = clot_val.drop('CLOT', axis=1)\n","clot_testing_labels = clot_test['CLOT']\n","clot_testing_features = clot_test.drop('CLOT', axis=1)\n","clot_training_original_labels = clot_train_original['CLOT']\n","clot_training_original_features = clot_train_original.drop('CLOT', axis=1)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" one-hot encoding"],"metadata":{}},{"source":["clot_train_features_oh = one_hot_encode(clot_train_features)\n","clot_valid_features_oh = one_hot_encode(clot_valid_features)\n","clot_test_features_oh = one_hot_encode(clot_testing_features)\n","clot_train_features_original_oh = one_hot_encode(clot_training_original_features)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" train models"],"metadata":{}},{"source":["logit_mod_ncg_clot = sm.Logit(clot_train_labels, clot_train_features_oh)\n","logit_res_ncg_clot = logit_mod_ncg_clot.fit(maxiter=500, method='ncg')\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" predictions on testing data"],"metadata":{}},{"source":["preds_ncg_clot = logit_res_ncg_clot.predict(exog=clot_test_features_oh)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["generate_results_roc(clot_testing_labels, preds_ncg_clot)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" training - oversampled"],"metadata":{}},{"source":["preds_ncg_clot_train = logit_res_ncg_clot.predict(exog=clot_train_features_oh)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["generate_results_roc(clot_train_labels, preds_ncg_clot_train)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" training - not oversampled, report in paper"],"metadata":{}},{"source":["preds_ncg_clot_train_original = logit_res_ncg_clot.predict(exog=clot_train_features_original_oh)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["generate_results_roc(clot_training_original_labels, preds_ncg_clot_train_original)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" validation"],"metadata":{}},{"source":["preds_ncg_clot_valid = logit_res_ncg_clot.predict(exog=clot_valid_features_oh)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["generate_results_roc(clot_valid_labels, preds_ncg_clot_valid)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### save predictions"],"metadata":{}},{"cell_type":"markdown","source":[" leak"],"metadata":{}},{"source":["test_preds_leak = pd.DataFrame(preds_ncg)\n","test_preds_leak.rename(columns = {0:'lr_leak_test'}, inplace = True)\n","test_preds_leak.to_csv('results/study_models_LEAK/LEAK_logistic_preds_test')\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["valid_preds_leak = pd.DataFrame(preds_ncg_valid)\n","valid_preds_leak.rename(columns = {0:'lr_leak_valid'}, inplace = True)\n","valid_preds_leak.to_csv('results/study_models_LEAK/LEAK_logistic_preds_valid')\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["train_preds_leak = pd.DataFrame(preds_ncg_train_original)\n","train_preds_leak.rename(columns = {0:'lr_leak_train'}, inplace = True)\n","train_preds_leak.to_csv('results/study_models_LEAK/LEAK_logistic_preds_train')\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" clot"],"metadata":{}},{"source":["test_preds_clot = pd.DataFrame(preds_ncg_clot)\n","test_preds_clot.rename(columns = {0:'lr_clot_test'}, inplace = True)\n","test_preds_clot.to_csv('results/study_models_CLOT/CLOT_logistic_preds_test')\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["valid_preds_clot = pd.DataFrame(preds_ncg_clot_valid)\n","valid_preds_clot.rename(columns = {0:'lr_clot_valid'}, inplace = True)\n","valid_preds_clot.to_csv('results/study_models_CLOT/CLOT_logistic_preds_valid')\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["train_preds_clot = pd.DataFrame(preds_ncg_clot_train_original)\n","train_preds_clot.rename(columns = {0:'lr_clot_train'}, inplace = True)\n","train_preds_clot.to_csv('results/study_models_CLOT/CLOT_logistic_preds_train')\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ## outputting tables\n","\n"," get LR coefficients into the same format as the XGB var importance strings.\n","\n"," handle it programatically. There are a few manipulation steps but worth it to avoid manual mapping and associated errors.\n","\n"," Ideally, this would have been set up up-front."],"metadata":{}},{"source":["#cat_ord\n","coeff_desc_dict = {}\n","coeff_rank_dict = {}\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["for key in cat_ord.keys():\n","    for i,j in enumerate(cat_ord[key]):\n","        coeff_string = key + '_' + str(i)\n","        descriptor_string = cat_ord[key][i]\n","        coeff_desc_dict[coeff_string] = descriptor_string\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["i = 0\n","for key in coeff_desc_dict.keys():\n","    coeff_rank_dict[key] = i\n","    i += 1\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# from https://stackoverflow.com/questions/51734180/converting-statsmodels-summary-object-to-pandas-dataframe?rq=1\n","def results_summary_to_dataframe(results):\n","    '''take the result of an statsmodel results table and transforms it into a dataframe'''\n","    pvals = results.pvalues\n","    coeff = results.params\n","    conf_lower = results.conf_int()[0]\n","    conf_higher = results.conf_int()[1]\n","\n","    results_df = pd.DataFrame({\"pvals\":pvals,\n","                               \"coeff\":coeff,\n","                               \"conf_lower\":conf_lower,\n","                               \"conf_higher\":conf_higher\n","                                })\n","    results_df.reset_index(drop=False, inplace=True)\n","\n","    for i in ref_cats_list:\n","        results_df = results_df.append({'index':i} , ignore_index=True)\n","    \n","    results_df['odds_ratio'] = np.exp(results_df['coeff'])\n","    results_df['odds_ratio_lower'] = np.exp(results_df['conf_lower'])\n","    results_df['odds_ratio_higher'] = np.exp(results_df['conf_higher'])\n","    \n","    results_df = results_df.round(3)\n","    \n","    results_df['p_round'] = np.where(results_df['pvals'] >= 0.001, results_df['pvals'], '< 0.001')\n","\n","    return results_df\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["r_logit_res_ncg = results_summary_to_dataframe(logit_res_ncg)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["r_logit_res_ncg['desc'] = list(r_logit_res_ncg['index'].map(coeff_desc_dict))\n","r_logit_res_ncg['rank'] = list(r_logit_res_ncg['index'].map(coeff_rank_dict))\n","r_logit_res_ncg.sort_values(by='rank', inplace=True)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["r_logit_res_clot_ncg = results_summary_to_dataframe(logit_res_ncg_clot)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["r_logit_res_clot_ncg['desc'] = list(r_logit_res_clot_ncg['index'].map(coeff_desc_dict))\n","r_logit_res_clot_ncg['rank'] = list(r_logit_res_clot_ncg['index'].map(coeff_rank_dict))\n","r_logit_res_clot_ncg.sort_values(by='rank', inplace=True)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["r_logit_res_ncg.to_csv('results/study_models_LEAK/lr_leak_coeffs.csv')\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["r_logit_res_clot_ncg.to_csv('results/study_models_CLOT/lr_clot_coeffs.csv')\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" these tables are not fully formatted. the rest of the details are taken care of in ms office"],"metadata":{}},{"source":["r_logit_res_ncg['abs_or'] = 1 - abs(r_logit_res_ncg['odds_ratio'])\n","r_logit_res_ncg.sort_values(by='abs_or').head(20)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["r_logit_res_clot_ncg['abs_or'] = 1 - abs(r_logit_res_ncg['odds_ratio'])\n","r_logit_res_clot_ncg.sort_values(by='abs_or').head(20)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["\n","\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}